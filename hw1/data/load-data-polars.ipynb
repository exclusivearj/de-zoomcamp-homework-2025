{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports go here\n",
    "import polars as pl\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adbc_driver_postgresql.dbapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow.Table\n",
      "count: int64\n",
      "----\n",
      "count: [[0]]\n"
     ]
    }
   ],
   "source": [
    "user=\"postgres\"\n",
    "password=\"postgres\"\n",
    "db_name = \"ny_taxi\"\n",
    "port=5433\n",
    "hostname=\"localhost\"\n",
    "DATABASE_URL = f\"postgresql://{user}:{password}@{hostname}:{port}/{db_name}\"\n",
    "\n",
    "conn = adbc_driver_postgresql.dbapi.connect(DATABASE_URL)\n",
    "\n",
    "# Create a cursor instance\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT count(1) FROM yellow_taxi_data_polars;\")\n",
    "    print(cur.fetch_arrow_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2019-01.csv.gz\"\n",
    "endpoint = \"hw1/data/yellow_tripdata_2019-01.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yellow_taxi_polars_schema() -> dict:\n",
    "  return {\n",
    "    \"VendorID\": pl.Int32,\n",
    "    \"tpep_pickup_datetime\": pl.Datetime,\n",
    "    \"tpep_dropoff_datetime\": pl.Datetime,\n",
    "    \"passenger_count\": pl.Int8,\n",
    "    \"trip_distance\": pl.Float64,\n",
    "    \"PULocationID\": pl.Int32,\n",
    "    \"DOLocationID\": pl.Int32,\n",
    "    \"RatecodeID\": pl.Int8,\n",
    "    \"store_and_fwd_flag\": pl.String,\n",
    "    \"payment_type\": pl.Int8,\n",
    "    \"fare_amount\": pl.Float64,\n",
    "    \"extra\": pl.Float64,\n",
    "    \"mta_tax\": pl.Float64,\n",
    "    \"improvement_surcharge\": pl.Float64,\n",
    "    \"tip_amount\": pl.Float64,\n",
    "    \"tolls_amount\": pl.Float64,\n",
    "    \"total_amount\": pl.Float64,\n",
    "    \"congestion_surcharge\": pl.Float64,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pl.read_csv(endpoint, dtypes=yellow_taxi_polars_schema(), n_rows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_yellow_taxi_table(connection_string: str, table_name: str = \"yellow_taxi_data_polars\") -> None:\n",
    "    \"\"\"\n",
    "    Creates a PostgreSQL table for yellow taxi data using ADBC engine.\n",
    "    \n",
    "    Args:\n",
    "        connection_string: PostgreSQL connection string\n",
    "        table_name: Name of the table to create\n",
    "    \"\"\"\n",
    "    # Map Polars types to PostgreSQL types\n",
    "    pg_type_mapping = {\n",
    "        pl.Int32: \"INTEGER\",\n",
    "        pl.Int8: \"SMALLINT\",\n",
    "        pl.Float64: \"DOUBLE PRECISION\",\n",
    "        pl.Datetime: \"TIMESTAMP\",\n",
    "        pl.String: \"VARCHAR\"\n",
    "    }\n",
    "    \n",
    "    # Get the schema definition\n",
    "    schema = yellow_taxi_polars_schema()\n",
    "    \n",
    "    # Convert schema to PostgreSQL column definitions\n",
    "    columns = []\n",
    "    for column_name, polars_type in schema.items():\n",
    "        quoted_column_name = f'\"{column_name}\"'\n",
    "        pg_type = pg_type_mapping[polars_type]\n",
    "        columns.append(f\"{quoted_column_name} {pg_type}\")\n",
    "    \n",
    "    # Drop the table if it already exists\n",
    "    drop_table_sql = f\"DROP TABLE IF EXISTS {table_name};\"\n",
    "    print(f\"Drop table sql ==> {drop_table_sql}\")\n",
    "    # Create a cursor instance\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(drop_table_sql)\n",
    "        conn.commit()\n",
    "    \n",
    "    # Create the table definition SQL\n",
    "    nl = \",\\n        \"\n",
    "    create_table_sql = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "            {nl.join(columns)}\n",
    "        );\n",
    "        \"\"\"\n",
    "    \n",
    "    print(f\"Create table sql ==> {create_table_sql}\")\n",
    "    \n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(create_table_sql)\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop table sql ==> DROP TABLE IF EXISTS yellow_taxi_data_polars;\n",
      "Create table sql ==> \n",
      "        CREATE TABLE IF NOT EXISTS yellow_taxi_data_polars (\n",
      "            \"VendorID\" INTEGER,\n",
      "        \"tpep_pickup_datetime\" TIMESTAMP,\n",
      "        \"tpep_dropoff_datetime\" TIMESTAMP,\n",
      "        \"passenger_count\" SMALLINT,\n",
      "        \"trip_distance\" DOUBLE PRECISION,\n",
      "        \"PULocationID\" INTEGER,\n",
      "        \"DOLocationID\" INTEGER,\n",
      "        \"RatecodeID\" SMALLINT,\n",
      "        \"store_and_fwd_flag\" VARCHAR,\n",
      "        \"payment_type\" SMALLINT,\n",
      "        \"fare_amount\" DOUBLE PRECISION,\n",
      "        \"extra\" DOUBLE PRECISION,\n",
      "        \"mta_tax\" DOUBLE PRECISION,\n",
      "        \"improvement_surcharge\" DOUBLE PRECISION,\n",
      "        \"tip_amount\" DOUBLE PRECISION,\n",
      "        \"tolls_amount\" DOUBLE PRECISION,\n",
      "        \"total_amount\" DOUBLE PRECISION,\n",
      "        \"congestion_surcharge\" DOUBLE PRECISION\n",
      "        );\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "recreate_yellow_taxi_table(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk, took 0.237 second\n",
      "inserted another chunk, took 0.205 second\n",
      "inserted another chunk, took 0.202 second\n",
      "inserted another chunk, took 0.201 second\n",
      "inserted another chunk, took 0.199 second\n",
      "inserted another chunk, took 0.206 second\n",
      "inserted another chunk, took 0.200 second\n",
      "inserted another chunk, took 0.207 second\n",
      "inserted another chunk, took 0.211 second\n",
      "inserted another chunk, took 0.200 second\n",
      "inserted another chunk, took 0.198 second\n",
      "inserted another chunk, took 0.197 second\n",
      "inserted another chunk, took 0.201 second\n",
      "inserted another chunk, took 0.203 second\n",
      "inserted another chunk, took 0.195 second\n",
      "inserted another chunk, took 0.195 second\n",
      "inserted another chunk, took 0.201 second\n",
      "inserted another chunk, took 0.200 second\n",
      "inserted another chunk, took 0.196 second\n",
      "inserted another chunk, took 0.195 second\n",
      "inserted another chunk, took 0.212 second\n",
      "inserted another chunk, took 0.193 second\n",
      "inserted another chunk, took 0.194 second\n",
      "inserted another chunk, took 0.203 second\n",
      "inserted another chunk, took 0.196 second\n",
      "inserted another chunk, took 0.195 second\n",
      "inserted another chunk, took 0.196 second\n",
      "inserted another chunk, took 0.194 second\n",
      "inserted another chunk, took 0.189 second\n",
      "inserted another chunk, took 0.193 second\n",
      "inserted another chunk, took 0.201 second\n",
      "inserted another chunk, took 0.198 second\n",
      "inserted another chunk, took 0.195 second\n",
      "inserted another chunk, took 0.199 second\n",
      "inserted another chunk, took 0.195 second\n",
      "inserted another chunk, took 0.203 second\n",
      "inserted another chunk, took 0.203 second\n",
      "inserted another chunk, took 0.202 second\n",
      "inserted another chunk, took 0.201 second\n",
      "inserted another chunk, took 0.198 second\n",
      "inserted another chunk, took 0.205 second\n",
      "inserted another chunk, took 0.203 second\n",
      "inserted another chunk, took 0.196 second\n",
      "inserted another chunk, took 0.197 second\n",
      "inserted another chunk, took 0.213 second\n",
      "inserted another chunk, took 0.193 second\n",
      "inserted another chunk, took 0.213 second\n",
      "inserted another chunk, took 0.189 second\n",
      "inserted another chunk, took 0.200 second\n",
      "inserted another chunk, took 0.208 second\n",
      "inserted another chunk, took 0.193 second\n",
      "inserted another chunk, took 0.192 second\n",
      "inserted another chunk, took 0.198 second\n",
      "inserted another chunk, took 0.195 second\n",
      "inserted another chunk, took 0.196 second\n",
      "inserted another chunk, took 0.223 second\n",
      "inserted another chunk, took 0.195 second\n",
      "inserted another chunk, took 0.205 second\n",
      "inserted another chunk, took 0.208 second\n",
      "inserted another chunk, took 0.203 second\n",
      "inserted another chunk, took 0.205 second\n",
      "inserted another chunk, took 0.214 second\n",
      "inserted another chunk, took 0.191 second\n",
      "inserted another chunk, took 0.203 second\n",
      "inserted another chunk, took 0.208 second\n",
      "inserted another chunk, took 0.198 second\n",
      "inserted another chunk, took 0.209 second\n",
      "inserted another chunk, took 0.213 second\n",
      "inserted another chunk, took 0.208 second\n",
      "inserted another chunk, took 0.199 second\n",
      "inserted another chunk, took 0.211 second\n",
      "inserted another chunk, took 0.187 second\n",
      "inserted another chunk, took 0.200 second\n",
      "inserted another chunk, took 0.207 second\n",
      "inserted another chunk, took 0.259 second\n",
      "inserted another chunk, took 0.210 second\n",
      "inserted another chunk, took 0.201 second\n",
      "inserted another chunk, took 0.202 second\n",
      "inserted another chunk, took 0.204 second\n",
      "inserted another chunk, took 0.204 second\n",
      "inserted another chunk, took 0.193 second\n",
      "inserted another chunk, took 0.202 second\n",
      "inserted another chunk, took 0.200 second\n",
      "inserted another chunk, took 0.208 second\n",
      "inserted another chunk, took 0.197 second\n",
      "inserted another chunk, took 0.199 second\n",
      "inserted another chunk, took 0.202 second\n",
      "inserted another chunk, took 0.206 second\n",
      "inserted another chunk, took 0.204 second\n",
      "inserted another chunk, took 0.205 second\n",
      "inserted another chunk, took 0.209 second\n",
      "inserted another chunk, took 0.202 second\n",
      "inserted another chunk, took 0.212 second\n",
      "inserted another chunk, took 0.203 second\n",
      "inserted another chunk, took 0.208 second\n",
      "inserted another chunk, took 0.204 second\n",
      "inserted another chunk, took 0.192 second\n",
      "inserted another chunk, took 0.192 second\n",
      "inserted another chunk, took 0.192 second\n",
      "inserted another chunk, took 0.209 second\n",
      "Final insertion took 20.208105087280273 seconds\n"
     ]
    }
   ],
   "source": [
    "batch_reader = pl.read_csv_batched(\n",
    "    source = endpoint,\n",
    "    batch_size=100000,\n",
    "    schema_overrides=yellow_taxi_polars_schema(),\n",
    "    has_header=True,\n",
    "    separator=\",\",\n",
    "    try_parse_dates=True\n",
    ")\n",
    "\n",
    "batches = batch_reader.next_batches(n=100)\n",
    "\n",
    "start_time = time()\n",
    "for df in batches:\n",
    "  t_start = time()\n",
    "  df.write_database(\n",
    "    table_name=\"yellow_taxi_data_polars\",\n",
    "    connection=DATABASE_URL,\n",
    "    engine=\"adbc\",\n",
    "    if_table_exists=\"append\",\n",
    "  )\n",
    "  t_end = time()\n",
    "  print('inserted another chunk, took %.3f second' % (t_end - t_start))\n",
    "\n",
    "end_time = time()\n",
    "print(f\"Final insertion took {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow.Table\n",
      "count: int64\n",
      "----\n",
      "count: [[4012011]]\n"
     ]
    }
   ],
   "source": [
    "with conn.cursor() as cur:\n",
    "    cur.execute(\"SELECT count(1) FROM yellow_taxi_data_polars;\")\n",
    "    print(cur.fetch_arrow_table())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
