{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports go here\n",
    "import polars as pl\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import adbc_driver_postgresql.dbapi\n",
    "from adbc_driver_manager.dbapi import Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "user=\"postgres\"\n",
    "password=\"postgres\"\n",
    "db_name = \"ny_taxi\"\n",
    "port=5433\n",
    "hostname=\"localhost\"\n",
    "DATABASE_URL = f\"postgresql://{user}:{password}@{hostname}:{port}/{db_name}\"\n",
    "# TABLE_NAME=\"yellow_taxi_data_polars\"\n",
    "TABLE_NAME=\"green_taxi_data_polars\"\n",
    "ZONE_TABLE_NAME=\"taxi_zone_data_polars\"\n",
    "\n",
    "# ENDPOINT = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/yellow/yellow_tripdata_2019-01.csv.gz\"\n",
    "# ENDPOINT = \"hw1/data/yellow_tripdata_2019-01.csv.gz\"\n",
    "# ENDPOINT = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-10.csv.gz\"\n",
    "ENDPOINT = \"hw1/data/green_tripdata_2019-10.csv.gz\"\n",
    "ZONEDATA = \"hw1/data/taxi_zone_lookup.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cursor instance\n",
    "conn: Connection = adbc_driver_postgresql.dbapi.connect(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yellow_taxi_polars_schema() -> dict:\n",
    "  return {\n",
    "    \"VendorID\": pl.Int32,\n",
    "    \"tpep_pickup_datetime\": pl.Datetime,\n",
    "    \"tpep_dropoff_datetime\": pl.Datetime,\n",
    "    \"passenger_count\": pl.Int8,\n",
    "    \"trip_distance\": pl.Float64,\n",
    "    \"PULocationID\": pl.Int32,\n",
    "    \"DOLocationID\": pl.Int32,\n",
    "    \"RatecodeID\": pl.Int8,\n",
    "    \"store_and_fwd_flag\": pl.String,\n",
    "    \"payment_type\": pl.Int8,\n",
    "    \"fare_amount\": pl.Float64,\n",
    "    \"extra\": pl.Float64,\n",
    "    \"mta_tax\": pl.Float64,\n",
    "    \"improvement_surcharge\": pl.Float64,\n",
    "    \"tip_amount\": pl.Float64,\n",
    "    \"tolls_amount\": pl.Float64,\n",
    "    \"total_amount\": pl.Float64,\n",
    "    \"congestion_surcharge\": pl.Float64,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def green_taxi_polars_schema() -> dict:\n",
    "  return {\n",
    "    \"VendorID\": pl.Int32,\n",
    "    \"lpep_pickup_datetime\": pl.Datetime,\n",
    "    \"lpep_dropoff_datetime\": pl.Datetime,\n",
    "    \"store_and_fwd_flag\": pl.String,\n",
    "    \"RatecodeID\": pl.Int8,\n",
    "    \"PULocationID\": pl.Int32,\n",
    "    \"DOLocationID\": pl.Int32,\n",
    "    \"passenger_count\": pl.Int8,\n",
    "    \"trip_distance\": pl.Float64,\n",
    "    \"fare_amount\": pl.Float64,\n",
    "    \"extra\": pl.Float64,\n",
    "    \"mta_tax\": pl.Float64,\n",
    "    \"tip_amount\": pl.Float64,\n",
    "    \"tolls_amount\": pl.Float64,\n",
    "    \"ehail_fee\": pl.Float64,\n",
    "    \"improvement_surcharge\": pl.Float64,\n",
    "    \"total_amount\": pl.Float64,\n",
    "    \"payment_type\": pl.Int8,\n",
    "    \"trip_type\" : pl.Int8,\n",
    "    \"congestion_surcharge\": pl.Float64,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxi_zone_polars_schema() -> dict:\n",
    "  return {\n",
    "    \"LocationID\": pl.Int32,\n",
    "    \"Borough\": pl.String,\n",
    "    \"Zone\": pl.String,\n",
    "    \"service_zone\": pl.String,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pl.read_csv(ENDPOINT, dtypes=green_taxi_polars_schema(), n_rows=100)\n",
    "# df = pl.read_csv(ENDPOINT, schema_overrides=green_taxi_polars_schema(), n_rows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_table(conn: Connection, schema: dict, table_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Creates a PostgreSQL table for yellow taxi data using ADBC engine.\n",
    "    \n",
    "    Args:\n",
    "        connection_string: PostgreSQL connection string\n",
    "        table_name: Name of the table to create\n",
    "    \"\"\"\n",
    "    # Map Polars types to PostgreSQL types\n",
    "    pg_type_mapping = {\n",
    "        pl.Int32: \"INTEGER\",\n",
    "        pl.Int8: \"SMALLINT\",\n",
    "        pl.Float64: \"DOUBLE PRECISION\",\n",
    "        pl.Datetime: \"TIMESTAMP\",\n",
    "        pl.String: \"VARCHAR\"\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Convert schema to PostgreSQL column definitions\n",
    "    columns = []\n",
    "    for column_name, polars_type in schema.items():\n",
    "        quoted_column_name = f'\"{column_name}\"'\n",
    "        pg_type = pg_type_mapping[polars_type]\n",
    "        columns.append(f\"{quoted_column_name} {pg_type}\")\n",
    "    \n",
    "    # Drop the table if it already exists\n",
    "    drop_table_sql = f\"DROP TABLE IF EXISTS {table_name};\"\n",
    "    print(f\"Drop table sql ==> {drop_table_sql}\")\n",
    "    # Create a cursor instance\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(drop_table_sql)\n",
    "        conn.commit()\n",
    "    \n",
    "    # Create the table definition SQL\n",
    "    nl = \",\\n        \"\n",
    "    create_table_sql = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "            {nl.join(columns)}\n",
    "        );\n",
    "        \"\"\"\n",
    "    \n",
    "    print(f\"Create table sql ==> {create_table_sql}\")\n",
    "    \n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(create_table_sql)\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop table sql ==> DROP TABLE IF EXISTS taxi_zone_data_polars;\n",
      "Create table sql ==> \n",
      "        CREATE TABLE IF NOT EXISTS taxi_zone_data_polars (\n",
      "            \"LocationID\" INTEGER,\n",
      "        \"Borough\" VARCHAR,\n",
      "        \"Zone\" VARCHAR,\n",
      "        \"service_zone\" VARCHAR\n",
      "        );\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# recreate_table(conn, green_taxi_polars_schema(), TABLE_NAME)\n",
    "recreate_table(conn, taxi_zone_polars_schema(), ZONE_TABLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_read_and_insert_into_db(source: str, schema: dict, table_name: str) -> None:\n",
    "  batch_reader = pl.read_csv_batched(\n",
    "      source = source,\n",
    "      batch_size=100000,\n",
    "      schema_overrides=schema,\n",
    "      has_header=True,\n",
    "      separator=\",\",\n",
    "      try_parse_dates=True\n",
    "  )\n",
    "\n",
    "  batches = batch_reader.next_batches(n=10000)\n",
    "\n",
    "  start_time = time()\n",
    "  for df in batches:\n",
    "    t_start = time()\n",
    "    df.write_database(\n",
    "      table_name,\n",
    "      connection=conn,\n",
    "      engine=\"adbc\",\n",
    "      if_table_exists=\"append\",\n",
    "    )\n",
    "    t_end = time()\n",
    "    print('inserted another chunk, took %.3f second' % (t_end - t_start))\n",
    "\n",
    "  end_time = time()\n",
    "  print(f\"Final insertion took {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_count(table_name: str)->int:\n",
    "  with conn.cursor() as cur:\n",
    "    cur.execute(f\"SELECT count(1) FROM {table_name};\")\n",
    "    # print(cur.fetch_arrow_table())\n",
    "    return cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_read_and_insert_into_db(ENDPOINT, green_taxi_polars_schema(), TABLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk, took 0.014 second\n",
      "inserted another chunk, took 0.003 second\n",
      "inserted another chunk, took 0.002 second\n",
      "inserted another chunk, took 0.002 second\n",
      "Final insertion took 0.02232503890991211 seconds\n"
     ]
    }
   ],
   "source": [
    "batch_read_and_insert_into_db(ZONEDATA, taxi_zone_polars_schema(), ZONE_TABLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "476386"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_row_count(TABLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_row_count(ZONE_TABLE_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
